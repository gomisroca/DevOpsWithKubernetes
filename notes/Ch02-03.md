# Introduction to Networking

We will open an endpoint to the app and access it via HTTP now.

We can forward a local port to a pod with `kubectl port-forward <pod-name> <local-port>:<remote-port>`. It is not meant for production, but it is very useful for debugging and development.

External connection with Docker were very simple (`-p 3003:3000`). With Kubernetes, it is a bit more complicated, and we will need to use either a _Service_ resource, an _Ingress_ resource, or the most recent solution, the _Gateway API_.

Since we are using k3d, we need a way to access the cluster from inside the Docker containers. With `docker ps` we can see k3d has prepared a port to acces the Kubernetes API via load balancer, which proxies request to port 6443 on the server node. We also see port 80 is open in the load balancer.

We have one server node and two agent nodes. For testing purposes, we will want to open a port for one of the agent nodes. We will delete the current cluster with `k3d cluster delete`, and create a new one with an open port to the load balancer and another port to an agent node: `k3d cluster create --port 8082:30080@agent:0 -p 8081:80@loadbalancer --agents 2`. Now we have access to our server node on port 8081 and to one of our agents nodes on 8082.

### What is a Service?

Given that pods are ephemeral, communication with the app cannot depend on the presence of any specific pod.

Services ensure the app can be reached from outside and from within the cluster. These resources handle the routing and load balancing to ensure the communication.

To start, we create `/manifests/service.yaml`. It will have to declare we want a Service, what port we want to listen to, what app the request should be routed to and the port where the request should be routed to.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: hashresponse-svc
spec:
  type: NodePort
  selector:
    app: hashresponse # This is the app as declared in the deployment.
  ports:
    - name: http
      nodePort: 30080 # This is the port that is available outside. Value for nodePort can be between 30000-32767
      protocol: TCP
      port: 1234 # This is a port that is available to the cluster, in this case it can be ~ anything
      targetPort: 3000 # This is the target port
```

We've defined a NodePort, which are ports that are exposed to the whole cluster. They are not flexible and require a different port for every application, so they are not used in production, but good to know for development. What we would use in production is a LoadBalancer, but that requires a cloud provider.

### What is an Ingress?

Incoming Network Access resource Ingress is implemented by different "controllers". That means ingresses don't work automatically, we need to choose a controller. K3s comes with Traefik.

To switch to Ingress, we will need to create an Ingress resource. It will route incoming traffic to a Service, but our old NodePort service will not work anymore, so we need to change it. Instead, we will use a ClusterIP service, which gives the service an internal IP within the cluster.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: hashresponse-svc
spec:
  type: ClusterIP
  selector:
    app: hashresponse
  ports:
    - port: 2345
      protocol: TCP
      targetPort: 3000
```

Now we can define our `/manifests/ingress.yaml` file:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: dwk-material-ingress
spec:
  rules:
    - http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: hashresponse-svc
                port:
                  number: 2345
```

It simply takes the port of the Service and routes all traffic to it.
