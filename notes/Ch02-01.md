# First Deploy

Microservices are small, autonomous services that work together.

Top reasons for microservices:

- Zero-downtime independent deployments
- Isolation of data and of processing around that data
- Reflect the organizational structure

Let's say we have 3 processes, we have 2 computers, and neither can run all 3 processes at the same time. We would have to decide which process to run on which computer, but then we have to see how we fit them, which consume more, what if we wanted to add another process, etc. This is where Kubernetes comes in.

With Kubernetes, we can simply define "This process should have 6 copies using X amount of resources". Kubernetes will then decide which computers to run on, and how to allocate the resources.

A cluster is a group of machines that work together. K8s clusters can be any size, i.e. a single node cluster would be one machine that hosts the k8s control-plane (exposiong API and mantaining the cluster).

We will use "server node" to refer to nodes with control-plane, and "agent node" to refer to nodes without control-plane.

Creating a cluster with k3d is as simple as `k3d cluster create -a 2`. This will create a cluster with 2 agent nodes. We can check it exists with `docker ps`. We will see that port 6443 is exposed as a load balancer, which will redirect connections to the server node. That's how we access the contents of the cluster. We can opt out of the load balanced with the flag `--no-lb`.

K3d also setup a kubeconfig file, which organizes information about the clusters, users, namespaces and authentication mechanisms. We can see the contents of the kubeconfig file with `k3d kubeconfig get k3s-default`.

We can use `kubectl` to interact with the cluster. We can get some info about the cluster with `kubectl cluster-info`, and we can see the nodes with `kubectl get nodes`. Furthermore, we can start/stop the cluster with `k3d cluster stop/start`. We can also delete the cluster with `k3d cluster delete`.

### Preparing for first deploy

To deploy an image, we need the cluster to have access to the image. We will use Docker Hub as our image registry. K3d allows local images with `k3d image import <image-name>` too.

To deploy an application, we will need to create a deployment with the image:
`kubectl create deployment <deployment-name> --image=<image-name>`

This will create a **deployment** and a **pod**.

A Pod is an abstraction of a group of containers that are running on the same node. They share the same network, storage, and other resources. Like a container of containers.

In k8s, all entities that exist are called **objects**. We can list objects in a resource with `kubectl get <resource-name>`. i.e. `kubectl get pods` will list all pods in the cluster.

A deployment resource is a way to tell k8s what container we want, how they should run, and how many of them should be running. When we created the deployment, a ReplicaSet obj was created as awell, which are used to tell how many replicas of a Pod we want. It will delete/create Pods until the desired number of replicas is reached.

We can see the output of a pod with `kubectl logs -f <pod-name>`.

### The Course Project

During the course we will develop a simple todo app with CRUD operations and many microservices.

### Declarative configuration with YAML

We used `kubectl create deployment hashgenerator-dep --image=jakousa/dwk-app1` to create a deployment. If we wanted to scale it 4 times, we could use the `--replicas=4` flag. But things start to get complicated, so we will use YAML to define our deployments.

It goes in `manifests/deployment.yaml`, and looks like this:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hashgenerator-dep
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hashgenerator
  template:
    metadata:
      labels:
        app: hashgenerator
    spec:
      containers:
        - name: hashgenerator
          image: jakousa/dwk-app1:b7fc18de2376da80ff0cfc72cf581a9f94d10e64
```

What we know so far:

- kind - the type of object
- name - the name of the object
- replicas - the number of replicas

Finally, we apply the deployment with `kubectl apply -f manifests/deployment.yaml`.
We can also apply manifests from the internet like, `kubectl apply -f https://raw.githubusercontent.com/kubernetes-hy/material-example/master/app1/manifests/deployment.yaml`.

When updating anything in Kubernetes, deleting is an anti-pattern. We should use tags to version our deplotments.

Creating a new deployment won't update the application unless the image tag is changed. Our basic workflow for now might look like this:  
`docker build -t <image>:<new_tag>`  
`docker push <image>:<new_tag>`  
`kubectl apply -f manifests/deployment.yaml`

This is not ideal, and we will have better ways of doing this in the future.
