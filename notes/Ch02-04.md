# Introduction to Storage

Unlike most aspects of Kubernetes, which are dynamic and capable of shifting between nodes and replicating, storage presents unique challenges and limitations.

A volume in Docker is the way to persist data. In K8s, there are several types of volumes.

### emptyDir volumes

The simple k8s volume. They are shared fs inside a pod, so their lifecycle is tied to the pod. When the pod is destroyed, the data is lost. If we move the pod to another node, the data will be lost too. So it is not good for backing up a database, for example, but it can be useful as cache, as it persists between container restarts, or to share files between two containers in a pod.

For example, we will share simple log files between two apps:

- _image finder_ will check if `/usr/src/app/files/image.jpg` exists, and if not, it will download a random image from the internet.
- _image responder_ will check if `/usr/src/app/files/image.jpg` exists, and show it if it does.

Both apps will share a deployment, so they will be inside the same pod. The deployment.yaml will look like this:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: images-dep
spec:
  replicas: 1
  selector:
    matchLabels:
      app: images
  template:
    metadata:
      labels:
        app: images
    spec:
      volumes: # Define volume
        - name: shared-image
          emptyDir: {}
      containers:
        - name: image-finder
          image: jakousa/dwk-app3-image-finder:b7fc18de2376da80ff0cfc72cf581a9f94d10e64
          volumeMounts: # Mount volume
            - name: shared-image
              mountPath: /usr/src/app/files
        - name: image-response
          image: jakousa/dwk-app3-image-response:b7fc18de2376da80ff0cfc72cf581a9f94d10e64
          volumeMounts: # Mount volume
            - name: shared-image
              mountPath: /usr/src/app/files
```

The deployment defines an emptyDir vol named `shared-image`. Both containers within the deployment mount the volume to `/usr/src/app/files`.

### Persistent Volumes

A Persistent Volume (PV) is a cluster-wide resource, created by the cluster admin or dynamically, and that can be backed into local disk, NFS, cloud, etc.

PVs lifecycle is independent of any pod that uses them. When using a cloud provider, it is them that will be responsible for backing up the data. If we run our own cluster, we can use a local PV that uses a path in the cluster node as storage. If that node is unavailable, the storage will be unusable.

For PV to work we first need to create a local path in the node we will bind to. We will create a `/tmp/kube` dir in the container `k3d-k3s-default-agent-0`, via the cmd `docker exec k3d-k3s-default-agent-0 mkdir -p /tmp/kube`.

The PV definition is created in `persistentvolume.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: example-pv
spec:
  storageClassName: my-example-pv # this is the name you are using later to claim this volume
  capacity:
    storage: 1Gi # Could be e.q. 500Gi. Small amount is to preserve space when testing locally
  volumeMode: Filesystem # This declares that it will be mounted into pods as a directory
  accessModes:
    - ReadWriteOnce
  local:
    path: /tmp/kube
  nodeAffinity: ## This is only required for local, it defines which nodes can access it
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - k3d-k3s-default-agent-0
```

In order to use the PV, we need to create a Persistent Volume Claim (PVC), a request for storage. When the user creates a PVC, k8s will try to find a fitting PV, or it might create one if it doesn't exist. Once bound, the PVC can only be used by one pod.

We can create a PVC in the file `persistentvolumeclaim.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: image-claim # name of the volume claim, this will be used in the deployment
spec:
  storageClassName: my-example-pv # this is the name of the persistent volume we are claiming
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
```

And now we can modify the earlier deployment to use the PVC:

```yaml
# ...
spec:
  volumes:
    - name: shared-image
      persistentVolumeClaim:
        claimName: image-claim
  containers:
    - name: image-finder
      image: jakousa/dwk-app3-image-finder:b7fc18de2376da80ff0cfc72cf581a9f94d10e64
      volumeMounts:
        - name: shared-image
          mountPath: /usr/src/app/files
    - name: image-response
      image: jakousa/dwk-app3-image-response:b7fc18de2376da80ff0cfc72cf581a9f94d10e64
      volumeMounts:
        - name: shared-image
          mountPath: /usr/src/app/files
```

Lastly, we will apply the PV and PVC to the cluster with `kubectl apply -f /manifests/deployment.yaml`. If we now delete the deployment and apply it again, the data will be persistent.
