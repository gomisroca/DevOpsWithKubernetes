# StatefulSets and Jobs

### StatefulSets

Deployments create and scales replicas of the same container. If we use a volume in a deployment, the volume will be shared by all replicas. For read-only this is ok, for read-write, this can cause big problems.

StatefulSets are similar to Deployments, but they make sure if a pod dies, the replacement is identical, with the same network id and name. If the pod is scaled, each copy will get its own storage. StatefulSets are for stateful applications, where state is stored inside the app, such as databases. The associated volumes are not deleted when the StatefulSet is deleted.

StatefulSet requires a "Headless Service" responsible for the network id. We can have a headless service with no proxying or load balancing with `clusterIP: None`. The `service.yaml` file looks like this:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: redis-svc
  labels:
    app: redis
spec:
  ports:
    - port: 6379
      name: web
  clusterIP: None
  selector:
    app: redisapp
```

Then we can create the `statefulset.yaml` file with two containers, `Redis` and `redisfiller`:

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-stset
spec:
  serviceName: redis-svc
  replicas: 2
  selector:
    matchLabels:
      app: redisapp
  template:
    metadata:
      labels:
        app: redisapp
    spec:
      containers:
        - name: redisfiller
          image: jakousa/dwk-app5:54203329200143875187753026f4e93a1305ae26
        - name: redis
          image: redis:5.0
          ports:
            - name: web
              containerPort: 6379
          volumeMounts:
            - name: redis-data-storage
              mountPath: /data
  volumeClaimTemplates:
    - metadata:
        name: redis-data-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: local-path
        resources:
          requests:
            storage: 100Mi
```

Since both containers are in the same pod, they will share the same network and `redisfiller` will see `Redis` at `localhost:6379`.

The main difference with a Deployment is that we need to specify the `volumeClaimTemplates` in the `statefulset.yaml` file. Since we use the dynamically provisioned `storageClassName: local-path`, we don't need to create a `PersistentVolume` and `PersistentVolumeClaim` for the volume. `volumeClaimTemplates` will be used to create individual volumes for each replica. Each replica will have its own volume, IP, domain name, and even if they die, the new one will have the same.

### Combining Resource Definitions in One File

We can define both the StatefulSet and the Headless Service in the same file by separating them with `---`.

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-stset
spec:
  serviceName: redis-svc
  replicas: 2
  selector:
    matchLabels:
      app: redisapp
  # more rows
---
apiVersion: v1
kind: Service
metadata:
  name: redis-svc
  labels:
    app: redis
spec:
  ports:
    - port: 6379
      name: web
  clusterIP: None
  selector:
    app: redisapp
```

The same can be done with Deployments and Services, etc.

### Jobs and CronJobs

The Job resource is used to run workloads that are not continuously running. The status of a job is saved and can be monitored. They can be configured to run multiple instances of the same task concurrently, sequentially, or until a number of successes have been reached.

A common example of a Job is to create backups of a database. For example, we will have a PG database and use pg_dump as the backup creation tool. Now, we can create a bash script:

```bash
#!/usr/bin/env bas
set -e

if [ $URL ]
then
  pg_dump -v $URL > /usr/src/app/backup.sql

  echo "Not sending the dump actually anywhere"
  # curl -F 'data=@/usr/src/app/backup.sql' https://somewhere
fi
```

This script is available at jakousa/simple-backup-example, now we can create a Job that uses it:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: backup
spec:
  template:
    spec:
      containers:
        - name: backup
          image: jakousa/simple-backup-example
          env:
            - name: URL
              value: "postgres://postgres:example@postgres-svc:5432/postgres"
      restartPolicy: Never # We will only run it once
```

We could tell it to retry a set number of times with `backoffLimit`.
